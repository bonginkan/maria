{"version":3,"sources":["../src/simple-interactive-cli.ts"],"sourcesContent":["import { createInterface } from 'readline';\nimport chalk from 'chalk';\nimport { loadEnvironmentVariables, getEnvironmentStatus } from './utils/env-loader.js';\nimport * as fs from 'fs';\nimport * as path from 'path';\n\ninterface Command {\n  input: string;\n  output: string;\n  timestamp: Date;\n}\n\nexport class MariaCLI {\n  private rl: any;\n  private commands: Command[] = [];\n  private isProcessing = false;\n\n  constructor() {\n    // Load environment variables first\n    loadEnvironmentVariables();\n    \n    this.rl = createInterface({\n      input: process.stdin,\n      output: process.stdout,\n      prompt: chalk.cyan('‚û§ '),\n      terminal: true\n    });\n    \n    this.showWelcome();\n    this.setupHandlers();\n    this.startPrompt();\n  }\n\n  private showWelcome() {\n    const logo = `\n${chalk.bold.magenta('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó')}\n${chalk.bold.magenta('‚ïë')}                                                              ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}    ${chalk.bold.magenta('‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó')}                    ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}    ${chalk.bold.magenta('‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}    ${chalk.bold.magenta('‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}    ${chalk.bold.magenta('‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}    ${chalk.bold.magenta('‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}    ${chalk.bold.magenta('‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}                                                              ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}           ${chalk.bold.magenta('‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}           ${chalk.bold.magenta('‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}           ${chalk.bold.magenta('‚ñà‚ñà‚ïë‚ñë‚ñë‚ïö‚ïê‚ïù‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñë')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}           ${chalk.bold.magenta('‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñë‚ñë')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}           ${chalk.bold.magenta('‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}           ${chalk.bold.magenta('‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù')}                   ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}                                                              ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}          ${chalk.bold.magenta('AI-Powered Development Platform')}                    ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}              ${chalk.magenta('v1.0.0 | TypeScript Monorepo')}                     ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}                                                              ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}             ${chalk.bold.cyan('¬© 2025 Bonginkan Inc.')}                           ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïë')}                                                              ${chalk.bold.magenta('‚ïë')}\n${chalk.bold.magenta('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù')}\n`;\n\n    console.log(logo);\n    console.log(chalk.bold.cyan('üåü Welcome to MARIA CODE CLI! üåü\\n'));\n    \n    console.log(chalk.cyan('üìö Available Commands:'));\n    console.log(chalk.gray('  ‚Ä¢ /help            - Show available commands'));\n    console.log(chalk.gray('  ‚Ä¢ /clear           - Clear command history'));  \n    console.log(chalk.gray('  ‚Ä¢ /status          - Show system status'));\n    console.log(chalk.gray('  ‚Ä¢ /model           - Interactive AI model selector'));\n    console.log(chalk.gray('  ‚Ä¢ /init            - Initialize MARIA project'));\n    console.log(chalk.gray('  ‚Ä¢ mc chat          - Interactive AI chat mode'));\n    console.log(chalk.gray('  ‚Ä¢ mc paper         - Academic paper development'));\n    console.log(chalk.gray('  ‚Ä¢ mc slides        - Presentation creation'));\n    console.log(chalk.gray('  ‚Ä¢ mc init          - Initialize project'));\n    console.log(chalk.gray('  ‚Ä¢ exit             - Exit CLI\\n'));\n    \n    console.log(chalk.yellow('üí° Try typing: /help, mc chat, or any natural language question!'));\n    console.log(chalk.gray('Press Ctrl+C or type \"exit\" to quit\\n'));\n  }\n\n  private setupHandlers() {\n    this.rl.on('line', async (input: string) => {\n      if (this.isProcessing) {\n        console.log(chalk.yellow('‚è≥ Please wait for the current command to finish...'));\n        return;\n      }\n\n      const trimmed = input.trim();\n      \n      if (!trimmed) {\n        this.rl.prompt();\n        return;\n      }\n\n      if (trimmed.toLowerCase() === 'exit' || trimmed.toLowerCase() === 'quit') {\n        this.exit();\n        return;\n      }\n\n      await this.processCommand(trimmed);\n    });\n\n    this.rl.on('SIGINT', () => {\n      this.exit();\n    });\n\n    process.on('SIGINT', () => {\n      this.exit();\n    });\n  }\n\n  private startPrompt() {\n    this.rl.prompt();\n  }\n\n  private async processCommand(input: string) {\n    this.isProcessing = true;\n    \n    const command: Command = {\n      input,\n      output: '',\n      timestamp: new Date()\n    };\n\n    try {\n      let output = '';\n      \n      if (input.startsWith('/')) {\n        output = await this.handleSlashCommand(input);\n      } else if (input.toLowerCase().startsWith('mc ')) {\n        output = await this.handleMcCommand(input);\n      } else {\n        output = await this.handleChatMessage(input);\n      }\n\n      command.output = output;\n      this.commands.push(command);\n      \n      console.log('\\n' + chalk.green('‚úÖ Response:'));\n      console.log(output);\n      console.log(chalk.gray(`\\n[${command.timestamp.toLocaleTimeString()}] Command completed\\n`));\n      \n    } catch (error) {\n      const errorMsg = `‚ùå Error: ${error}`;\n      command.output = errorMsg;\n      this.commands.push(command);\n      console.log('\\n' + chalk.red(errorMsg) + '\\n');\n    } finally {\n      this.isProcessing = false;\n      this.rl.prompt();\n    }\n  }\n\n  private async handleSlashCommand(input: string): Promise<string> {\n    const parts = input.slice(1).toLowerCase().split(' ');\n    const command = parts[0];\n    const args = parts.slice(1);\n    \n    switch (command) {\n      case 'help':\n        return `üìö MARIA CODE CLI Help\n\nüîπ Slash Commands:\n  /help            - Show this help message\n  /clear           - Clear command history  \n  /status          - Show system status\n  /model           - Interactive AI model selector\n  /init            - Initialize MARIA project\n\nüîπ MC Commands:\n  mc chat          - Interactive AI chat mode\n  mc paper         - Academic paper development\n  mc slides        - Presentation creation\n  mc graph         - Neo4j knowledge graph\n  mc init          - Initialize project configuration\n\nüîπ Chat:\n  Type any natural language and I'll help you!\n  \nüí° Examples:\n  ‚Ä¢ \"Create a REST API for user management\"\n  ‚Ä¢ \"Help me debug this React component\"  \n  ‚Ä¢ \"Generate tests for my functions\"`;\n\n      case 'clear':\n        this.commands = [];\n        console.clear();\n        this.showWelcome();\n        return 'üßπ Command history cleared!';\n\n      case 'status':\n        return `üìä MARIA CODE CLI Status\n\nüü¢ System: Online\nüü¢ AI Agents: Ready  \nüü¢ Neo4j: Connected\nüì¶ Version: v1.0.0\n‚ö° Mode: Development\n\nüìà Session Stats:\n  Commands: ${this.commands.length}\n  Uptime: ${Math.floor(process.uptime())}s\n  Memory: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`;\n\n      case 'model':\n        return await this.handleModelCommand(args);\n\n      case 'init':\n        return await this.handleInitCommand();\n\n      default:\n        return `‚ùì Unknown slash command: /${command}\n\nType /help to see available commands.`;\n    }\n  }\n\n  private async handleModelCommand(args: string[] = []): Promise<string> {\n    const envStatus = getEnvironmentStatus();\n    \n    // If specific model requested\n    if (args.length > 0) {\n      const requestedModel = args[0];\n      const modelMap: Record<string, string> = {\n        'gpt-4o': 'gpt-4o',\n        'gpt4o': 'gpt-4o',\n        'claude-3-opus': 'claude-3-opus',\n        'claude3opus': 'claude-3-opus',\n        'opus': 'claude-3-opus',\n        'gemini': 'gemini-2.5-pro',\n        'gemini-2.5-pro': 'gemini-2.5-pro',\n        'mixtral': 'mixtral-8x7b',\n        'mixtral-8x7b': 'mixtral-8x7b',\n        'gpt-oss-120b': 'gpt-oss-120b',\n        '120b': 'gpt-oss-120b',\n        'gpt-oss-20b': 'gpt-oss-20b',\n        '20b': 'gpt-oss-20b',\n        'qwen3-30b': 'qwen3-30b',\n        'qwen30b': 'qwen3-30b',\n        'qwen2.5-vl': 'qwen2.5-vl',\n        'qwenvl': 'qwen2.5-vl'\n      };\n      \n      const modelId = requestedModel ? modelMap[requestedModel] : undefined;\n      if (modelId) {\n        // Update environment variables\n        if (modelId.includes('gpt-oss')) {\n          process.env.AI_PROVIDER = 'lmstudio';\n          process.env.LMSTUDIO_DEFAULT_MODEL = modelId;\n          process.env.OFFLINE_MODE = 'true';\n        } else {\n          process.env.AI_PROVIDER = 'openai'; // or appropriate provider\n          process.env.AI_MODEL = modelId;\n          process.env.OFFLINE_MODE = 'false';\n        }\n        \n        return `‚úÖ AI Model Updated Successfully!\n\nü§ñ Active Model: ${modelId}\nüìç Configuration updated in environment\nüí° Your next messages will use this model.\n\nüåü Ready to chat with ${modelId}!`;\n      } else {\n        return `‚ùå Invalid model: \"${requestedModel}\"\n\nüí° Available models: gpt-4o, claude-3-opus, gemini-2.5-pro, mixtral-8x7b, gpt-oss-120b, gpt-oss-20b, qwen3-30b, qwen2.5-vl`;\n      }\n    }\n\n    // Check LM Studio status\n    let lmStudioStatus = '‚ùå Not available';\n    if (process.env.LMSTUDIO_ENABLED === 'true') {\n      try {\n        const fetch = (await import('node-fetch')).default;\n        const response = await fetch('http://localhost:1234/v1/models', {\n          headers: { 'Authorization': 'Bearer lm-studio' },\n          signal: AbortSignal.timeout(2000)\n        });\n        lmStudioStatus = response.ok ? '‚úÖ Running' : '‚ö†Ô∏è Server not running';\n      } catch {\n        lmStudioStatus = '‚ö†Ô∏è Server not running';\n      }\n    }\n\n    // Show available models with status\n    return `ü§ñ AI Model Selection\n\n‚òÅÔ∏è Cloud Models:\n  ‚Ä¢ gpt-4o (OpenAI)          - High accuracy, multimodal\n  ‚Ä¢ claude-3-opus (Anthropic) - Long text, complex tasks  \n  ‚Ä¢ gemini-2.5-pro (Google)  - Research, analysis, vision\n  ‚Ä¢ mixtral-8x7b (Groq)      - Fast inference\n\nüíª Local Models:\n  ‚Ä¢ gpt-oss-120b (LM Studio)  - Complex reasoning (~64GB VRAM)\n  ‚Ä¢ gpt-oss-20b (LM Studio)   - Balanced performance (~12GB VRAM)  \n  ‚Ä¢ qwen3-30b (LM Studio)     - Multilingual support (~16GB VRAM)\n  ‚Ä¢ qwen2.5-vl (Ollama)      - Vision capabilities (~8GB VRAM)\n\nüîç **Current Status:**\n‚Ä¢ API Keys: ${envStatus.hasApiKeys ? '‚úÖ Configured' : '‚ùå Not found'}\n‚Ä¢ LM Studio: ${lmStudioStatus}\n‚Ä¢ Offline Mode: ${envStatus.offlineMode ? '‚úÖ Enabled' : '‚ùå Disabled'}\n‚Ä¢ Available Providers: ${envStatus.providers.join(', ')}\n\nüí° To select a model, use: /model [model-name]\n   Example: /model gpt-4o or /model 120b\n\nüöÄ **Quick Setup:**\n‚Ä¢ For 120B model: /model 120b\n‚Ä¢ For cloud models: Add API keys to .env.local\n‚Ä¢ For offline work: Run LM Studio first`;\n  }\n\n  private async handleInitCommand(): Promise<string> {\n    try {\n      const currentDir = process.cwd();\n      const configPath = path.join(currentDir, '.maria-code.toml');\n      const memoryPath = path.join(currentDir, 'MARIA.md');\n      \n      // Check if already initialized\n      if (fs.existsSync(configPath)) {\n        return `‚úÖ MARIA project already initialized!\n\nüìÅ Project: ${path.basename(currentDir)}\nüìç Location: ${currentDir}\n‚öôÔ∏è Config: .maria-code.toml\nüìù Memory: MARIA.md\n\nüí° Use /status to check project status\nüîß Use /model to configure AI models`;\n      }\n\n      // Create .maria-code.toml\n      const tomlConfig = `# MARIA CODE Configuration\n# AI-Powered Development Platform\n\n[project]\nname = \"${path.basename(currentDir)}\"\nversion = \"1.0.0\"\ndescription = \"MARIA AI-powered project\"\ncreated = \"${new Date().toISOString()}\"\n\n[ai]\ndefault_model = \"gemini-2.5-pro\"\nproviders = [\n  \"openai\",\n  \"anthropic\", \n  \"google\",\n  \"groq\",\n  \"lmstudio\",\n  \"ollama\"\n]\n\n[features]\nauto_mode = false\nlearning_mode = true\ncollaboration_mode = false\nmission_mode = false\n\n[integrations]\nneo4j_enabled = true\ngithub_enabled = true\nlm_studio_enabled = true\n\n[memory]\nfile = \"MARIA.md\"\nauto_save = true\ncontext_window = 128000\n\n[development]\ntypescript = true\ntesting = true\nlinting = true\nformatting = true\n`;\n\n      // Create MARIA.md memory file\n      const memoryContent = `# MARIA Memory\n\n## Project: ${path.basename(currentDir)}\n\n### Overview\n- **Created**: ${new Date().toLocaleDateString()}\n- **AI Model**: Gemini 2.5 Pro (default)\n- **Status**: Initialized\n\n### Project Structure\n\\`\\`\\`\n${currentDir}/\n‚îú‚îÄ‚îÄ .maria-code.toml    # Configuration\n‚îú‚îÄ‚îÄ MARIA.md           # AI memory & context\n‚îî‚îÄ‚îÄ ...                # Your project files\n\\`\\`\\`\n\n### AI Models Available\n- **Cloud Models**: GPT-4o, Claude 3 Opus, Gemini 2.5 Pro, Mixtral 8x7B\n- **Local Models**: GPT-OSS 120B, GPT-OSS 20B, Qwen3 30B, Qwen2.5-VL\n\n### Recent Commands\n- \\`/init\\` - Project initialized\n\n### Learning Notes\n<!-- AI will automatically update this section based on interactions -->\n\n---\n*This file is automatically managed by MARIA CODE AI*\n`;\n\n      // Write files\n      fs.writeFileSync(configPath, tomlConfig);\n      fs.writeFileSync(memoryPath, memoryContent);\n\n      return `üöÄ MARIA Project Initialized Successfully!\n\nüìÅ **Project**: ${path.basename(currentDir)}\nüìç **Location**: ${currentDir}\n\nüìÑ **Files Created**:\n  ‚úÖ .maria-code.toml - Project configuration\n  ‚úÖ MARIA.md - AI memory & learning context\n\nü§ñ **AI Configuration**:\n  ‚Ä¢ Default Model: Gemini 2.5 Pro\n  ‚Ä¢ Cloud & Local models available\n  ‚Ä¢ Learning mode: Enabled\n\nüîß **Next Steps**:\n  1. Use \\`/model\\` to configure AI models\n  2. Use \\`mc chat\\` to start AI conversations  \n  3. Use \\`mc read .\\` to analyze your codebase\n  4. Use \\`/status\\` to check system status\n\nüí° **Pro Tips**:\n  ‚Ä¢ MARIA.md tracks AI learning and project context\n  ‚Ä¢ Use natural language for complex development tasks\n  ‚Ä¢ LM Studio integration ready for local AI models\n\nüåü Welcome to AI-powered development with MARIA!`;\n\n    } catch (error) {\n      return `‚ùå Failed to initialize MARIA project: ${error instanceof Error ? error.message : 'Unknown error'}\n\nüí° Make sure you have write permissions in the current directory.`;\n    }\n  }\n\n  private async handleMcCommand(input: string): Promise<string> {\n    const args = input.split(' ').slice(1);\n    const command = args[0];\n\n    switch (command) {\n      case 'chat':\n        return `üí¨ Starting AI Chat Mode...\n\nü§ñ Hi! I'm MARIA, your AI development assistant.\nüìù How can I help you today?\n\nüí° Try asking me to:\n  ‚Ä¢ \"Create a REST API for user management\"\n  ‚Ä¢ \"Help me debug this React component\"\n  ‚Ä¢ \"Generate tests for my functions\"\n\nüîÑ I'm ready to help with any development task!`;\n\n      case 'paper':\n        return `üìÑ Academic Paper Development Mode\n\nüìö Features Available:\n  ‚Ä¢ LaTeX document generation\n  ‚Ä¢ BibTeX reference management\n  ‚Ä¢ Real-time collaboration\n  ‚Ä¢ Version control integration\n\nüìù Example usage:\n  mc paper --outline \"AI in Healthcare\"\n  mc paper --template ieee\n  mc paper --export pdf\n\n‚ú® Ready to help with your academic writing!`;\n\n      case 'slides':\n        return `üé® Presentation Creation Mode\n\nüéØ Features Available:\n  ‚Ä¢ AI-generated content\n  ‚Ä¢ Professional templates\n  ‚Ä¢ Visual design optimization\n  ‚Ä¢ Export to multiple formats\n\nüìù Example usage:\n  mc slides --structure \"AI in Healthcare\"\n  mc slides --template corporate\n  mc slides --export pptx\n\nüé™ Ready to create amazing presentations!`;\n\n      case 'graph':\n        return `üï∏Ô∏è Knowledge Graph (optional)\n\nüóÇÔ∏è Features Available:\n  ‚Ä¢ Graph data visualization\n  ‚Ä¢ Knowledge relationship mapping\n  ‚Ä¢ Cypher query interface\n  ‚Ä¢ Bloom integration\n\nüìù Example usage:\n  mc graph --query \"MATCH (n) RETURN n LIMIT 25\"\n  mc graph --visualize entities\n  mc graph --bloom\n\nüåê Ready to explore your knowledge graph!`;\n\n      case 'init':\n        return await this.handleInitCommand();\n\n      default:\n        return `‚ùì Unknown mc command: ${command}\n\nüìö Available MC commands:\n  ‚Ä¢ mc chat    - AI chat mode\n  ‚Ä¢ mc paper   - Academic paper development  \n  ‚Ä¢ mc slides  - Presentation creation\n  ‚Ä¢ mc graph   - Knowledge graph\n  ‚Ä¢ mc init    - Project initialization\n\nType /help for more information.`;\n    }\n  }\n\n  private async handleChatMessage(input: string): Promise<string> {\n    return `üí¨ Chat Response for: \"${input}\"\n\nü§ñ I understand you want help with: ${input}\n\nüîÑ Processing your natural language request...\n\nüí° Based on your input, I can help you with:\n  ‚Ä¢ Code generation and debugging\n  ‚Ä¢ Architecture planning\n  ‚Ä¢ Testing strategies  \n  ‚Ä¢ Documentation creation\n\nüöÄ To get started with full AI capabilities, use /model to select an AI model first!\n\nüí¨ For interactive chat, use: mc chat`;\n  }\n\n  private exit() {\n    console.log(chalk.cyan('\\nüëã Thank you for using MARIA CODE CLI!'));\n    console.log(chalk.gray('Session saved. See you next time!\\n'));\n    process.exit(0);\n  }\n}"],"mappings":";;;;;;;;;AAAA,SAAS,uBAAuB;AAGhC,YAAY,QAAQ;AACpB,YAAY,UAAU;AAQf,IAAM,WAAN,MAAe;AAAA,EACZ;AAAA,EACA,WAAsB,CAAC;AAAA,EACvB,eAAe;AAAA,EAEvB,cAAc;AAEZ,6BAAyB;AAEzB,SAAK,KAAK,gBAAgB;AAAA,MACxB,OAAO,QAAQ;AAAA,MACf,QAAQ,QAAQ;AAAA,MAChB,QAAQ,eAAM,KAAK,SAAI;AAAA,MACvB,UAAU;AAAA,IACZ,CAAC;AAED,SAAK,YAAY;AACjB,SAAK,cAAc;AACnB,SAAK,YAAY;AAAA,EACnB;AAAA,EAEQ,cAAc;AACpB,UAAM,OAAO;AAAA,EACf,eAAM,KAAK,QAAQ,kYAAkE,CAAC;AAAA,EACtF,eAAM,KAAK,QAAQ,QAAG,CAAC,iEAAiE,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EAC/G,eAAM,KAAK,QAAQ,QAAG,CAAC,OAAO,eAAM,KAAK,QAAQ,6LAAuC,CAAC,uBAAuB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,OAAO,eAAM,KAAK,QAAQ,iOAAwC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,OAAO,eAAM,KAAK,QAAQ,sOAAwC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,OAAO,eAAM,KAAK,QAAQ,sOAAwC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,OAAO,eAAM,KAAK,QAAQ,8LAAwC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,OAAO,eAAM,KAAK,QAAQ,+KAAwC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,iEAAiE,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EAC/G,eAAM,KAAK,QAAQ,QAAG,CAAC,cAAc,eAAM,KAAK,QAAQ,kMAAkC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACxI,eAAM,KAAK,QAAQ,QAAG,CAAC,cAAc,eAAM,KAAK,QAAQ,kMAAkC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACxI,eAAM,KAAK,QAAQ,QAAG,CAAC,cAAc,eAAM,KAAK,QAAQ,kMAAkC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACxI,eAAM,KAAK,QAAQ,QAAG,CAAC,cAAc,eAAM,KAAK,QAAQ,kMAAkC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACxI,eAAM,KAAK,QAAQ,QAAG,CAAC,cAAc,eAAM,KAAK,QAAQ,kMAAkC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACxI,eAAM,KAAK,QAAQ,QAAG,CAAC,cAAc,eAAM,KAAK,QAAQ,kMAAkC,CAAC,sBAAsB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACxI,eAAM,KAAK,QAAQ,QAAG,CAAC,iEAAiE,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EAC/G,eAAM,KAAK,QAAQ,QAAG,CAAC,aAAa,eAAM,KAAK,QAAQ,iCAAiC,CAAC,uBAAuB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACvI,eAAM,KAAK,QAAQ,QAAG,CAAC,iBAAiB,eAAM,QAAQ,8BAA8B,CAAC,wBAAwB,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACpI,eAAM,KAAK,QAAQ,QAAG,CAAC,iEAAiE,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EAC/G,eAAM,KAAK,QAAQ,QAAG,CAAC,gBAAgB,eAAM,KAAK,KAAK,0BAAuB,CAAC,8BAA8B,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EACpI,eAAM,KAAK,QAAQ,QAAG,CAAC,iEAAiE,eAAM,KAAK,QAAQ,QAAG,CAAC;AAAA,EAC/G,eAAM,KAAK,QAAQ,kYAAkE,CAAC;AAAA;AAGpF,YAAQ,IAAI,IAAI;AAChB,YAAQ,IAAI,eAAM,KAAK,KAAK,kDAAoC,CAAC;AAEjE,YAAQ,IAAI,eAAM,KAAK,+BAAwB,CAAC;AAChD,YAAQ,IAAI,eAAM,KAAK,qDAAgD,CAAC;AACxE,YAAQ,IAAI,eAAM,KAAK,mDAA8C,CAAC;AACtE,YAAQ,IAAI,eAAM,KAAK,gDAA2C,CAAC;AACnE,YAAQ,IAAI,eAAM,KAAK,2DAAsD,CAAC;AAC9E,YAAQ,IAAI,eAAM,KAAK,sDAAiD,CAAC;AACzE,YAAQ,IAAI,eAAM,KAAK,sDAAiD,CAAC;AACzE,YAAQ,IAAI,eAAM,KAAK,wDAAmD,CAAC;AAC3E,YAAQ,IAAI,eAAM,KAAK,mDAA8C,CAAC;AACtE,YAAQ,IAAI,eAAM,KAAK,gDAA2C,CAAC;AACnE,YAAQ,IAAI,eAAM,KAAK,wCAAmC,CAAC;AAE3D,YAAQ,IAAI,eAAM,OAAO,yEAAkE,CAAC;AAC5F,YAAQ,IAAI,eAAM,KAAK,uCAAuC,CAAC;AAAA,EACjE;AAAA,EAEQ,gBAAgB;AACtB,SAAK,GAAG,GAAG,QAAQ,OAAO,UAAkB;AAC1C,UAAI,KAAK,cAAc;AACrB,gBAAQ,IAAI,eAAM,OAAO,yDAAoD,CAAC;AAC9E;AAAA,MACF;AAEA,YAAM,UAAU,MAAM,KAAK;AAE3B,UAAI,CAAC,SAAS;AACZ,aAAK,GAAG,OAAO;AACf;AAAA,MACF;AAEA,UAAI,QAAQ,YAAY,MAAM,UAAU,QAAQ,YAAY,MAAM,QAAQ;AACxE,aAAK,KAAK;AACV;AAAA,MACF;AAEA,YAAM,KAAK,eAAe,OAAO;AAAA,IACnC,CAAC;AAED,SAAK,GAAG,GAAG,UAAU,MAAM;AACzB,WAAK,KAAK;AAAA,IACZ,CAAC;AAED,YAAQ,GAAG,UAAU,MAAM;AACzB,WAAK,KAAK;AAAA,IACZ,CAAC;AAAA,EACH;AAAA,EAEQ,cAAc;AACpB,SAAK,GAAG,OAAO;AAAA,EACjB;AAAA,EAEA,MAAc,eAAe,OAAe;AAC1C,SAAK,eAAe;AAEpB,UAAM,UAAmB;AAAA,MACvB;AAAA,MACA,QAAQ;AAAA,MACR,WAAW,oBAAI,KAAK;AAAA,IACtB;AAEA,QAAI;AACF,UAAI,SAAS;AAEb,UAAI,MAAM,WAAW,GAAG,GAAG;AACzB,iBAAS,MAAM,KAAK,mBAAmB,KAAK;AAAA,MAC9C,WAAW,MAAM,YAAY,EAAE,WAAW,KAAK,GAAG;AAChD,iBAAS,MAAM,KAAK,gBAAgB,KAAK;AAAA,MAC3C,OAAO;AACL,iBAAS,MAAM,KAAK,kBAAkB,KAAK;AAAA,MAC7C;AAEA,cAAQ,SAAS;AACjB,WAAK,SAAS,KAAK,OAAO;AAE1B,cAAQ,IAAI,OAAO,eAAM,MAAM,kBAAa,CAAC;AAC7C,cAAQ,IAAI,MAAM;AAClB,cAAQ,IAAI,eAAM,KAAK;AAAA,GAAM,QAAQ,UAAU,mBAAmB,CAAC;AAAA,CAAuB,CAAC;AAAA,IAE7F,SAAS,OAAO;AACd,YAAM,WAAW,iBAAY,KAAK;AAClC,cAAQ,SAAS;AACjB,WAAK,SAAS,KAAK,OAAO;AAC1B,cAAQ,IAAI,OAAO,eAAM,IAAI,QAAQ,IAAI,IAAI;AAAA,IAC/C,UAAE;AACA,WAAK,eAAe;AACpB,WAAK,GAAG,OAAO;AAAA,IACjB;AAAA,EACF;AAAA,EAEA,MAAc,mBAAmB,OAAgC;AAC/D,UAAM,QAAQ,MAAM,MAAM,CAAC,EAAE,YAAY,EAAE,MAAM,GAAG;AACpD,UAAM,UAAU,MAAM,CAAC;AACvB,UAAM,OAAO,MAAM,MAAM,CAAC;AAE1B,YAAQ,SAAS;AAAA,MACf,KAAK;AACH,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAwBT,KAAK;AACH,aAAK,WAAW,CAAC;AACjB,gBAAQ,MAAM;AACd,aAAK,YAAY;AACjB,eAAO;AAAA,MAET,KAAK;AACH,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cASD,KAAK,SAAS,MAAM;AAAA,YACtB,KAAK,MAAM,QAAQ,OAAO,CAAC,CAAC;AAAA,YAC5B,KAAK,MAAM,QAAQ,YAAY,EAAE,WAAW,OAAO,IAAI,CAAC;AAAA,MAE9D,KAAK;AACH,eAAO,MAAM,KAAK,mBAAmB,IAAI;AAAA,MAE3C,KAAK;AACH,eAAO,MAAM,KAAK,kBAAkB;AAAA,MAEtC;AACE,eAAO,kCAA6B,OAAO;AAAA;AAAA;AAAA,IAG/C;AAAA,EACF;AAAA,EAEA,MAAc,mBAAmB,OAAiB,CAAC,GAAoB;AACrE,UAAM,YAAY,qBAAqB;AAGvC,QAAI,KAAK,SAAS,GAAG;AACnB,YAAM,iBAAiB,KAAK,CAAC;AAC7B,YAAM,WAAmC;AAAA,QACvC,UAAU;AAAA,QACV,SAAS;AAAA,QACT,iBAAiB;AAAA,QACjB,eAAe;AAAA,QACf,QAAQ;AAAA,QACR,UAAU;AAAA,QACV,kBAAkB;AAAA,QAClB,WAAW;AAAA,QACX,gBAAgB;AAAA,QAChB,gBAAgB;AAAA,QAChB,QAAQ;AAAA,QACR,eAAe;AAAA,QACf,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,QACX,cAAc;AAAA,QACd,UAAU;AAAA,MACZ;AAEA,YAAM,UAAU,iBAAiB,SAAS,cAAc,IAAI;AAC5D,UAAI,SAAS;AAEX,YAAI,QAAQ,SAAS,SAAS,GAAG;AAC/B,kBAAQ,IAAI,cAAc;AAC1B,kBAAQ,IAAI,yBAAyB;AACrC,kBAAQ,IAAI,eAAe;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,cAAc;AAC1B,kBAAQ,IAAI,WAAW;AACvB,kBAAQ,IAAI,eAAe;AAAA,QAC7B;AAEA,eAAO;AAAA;AAAA,0BAEI,OAAO;AAAA;AAAA;AAAA;AAAA,+BAIF,OAAO;AAAA,MACzB,OAAO;AACL,eAAO,0BAAqB,cAAc;AAAA;AAAA;AAAA,MAG5C;AAAA,IACF;AAGA,QAAI,iBAAiB;AACrB,QAAI,QAAQ,IAAI,qBAAqB,QAAQ;AAC3C,UAAI;AACF,cAAM,SAAS,MAAM,OAAO,YAAY,GAAG;AAC3C,cAAM,WAAW,MAAM,MAAM,mCAAmC;AAAA,UAC9D,SAAS,EAAE,iBAAiB,mBAAmB;AAAA,UAC/C,QAAQ,YAAY,QAAQ,GAAI;AAAA,QAClC,CAAC;AACD,yBAAiB,SAAS,KAAK,mBAAc;AAAA,MAC/C,QAAQ;AACN,yBAAiB;AAAA,MACnB;AAAA,IACF;AAGA,WAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAeG,UAAU,aAAa,sBAAiB,kBAAa;AAAA,oBACpD,cAAc;AAAA,uBACX,UAAU,cAAc,mBAAc,iBAAY;AAAA,8BAC3C,UAAU,UAAU,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASrD;AAAA,EAEA,MAAc,oBAAqC;AACjD,QAAI;AACF,YAAM,aAAa,QAAQ,IAAI;AAC/B,YAAM,aAAkB,UAAK,YAAY,kBAAkB;AAC3D,YAAM,aAAkB,UAAK,YAAY,UAAU;AAGnD,UAAO,cAAW,UAAU,GAAG;AAC7B,eAAO;AAAA;AAAA,qBAEI,cAAS,UAAU,CAAC;AAAA,sBACxB,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAMnB;AAGA,YAAM,aAAa;AAAA;AAAA;AAAA;AAAA,UAIV,cAAS,UAAU,CAAC;AAAA;AAAA;AAAA,cAGtB,oBAAI,KAAK,GAAE,YAAY,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAqC/B,YAAM,gBAAgB;AAAA;AAAA,cAET,cAAS,UAAU,CAAC;AAAA;AAAA;AAAA,kBAGtB,oBAAI,KAAK,GAAE,mBAAmB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAM9C,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAqBN,MAAG,iBAAc,YAAY,UAAU;AACvC,MAAG,iBAAc,YAAY,aAAa;AAE1C,aAAO;AAAA;AAAA,yBAEU,cAAS,UAAU,CAAC;AAAA,0BACxB,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAwBzB,SAAS,OAAO;AACd,aAAO,8CAAyC,iBAAiB,QAAQ,MAAM,UAAU,eAAe;AAAA;AAAA;AAAA,IAG1G;AAAA,EACF;AAAA,EAEA,MAAc,gBAAgB,OAAgC;AAC5D,UAAM,OAAO,MAAM,MAAM,GAAG,EAAE,MAAM,CAAC;AACrC,UAAM,UAAU,KAAK,CAAC;AAEtB,YAAQ,SAAS;AAAA,MACf,KAAK;AACH,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAYT,KAAK;AACH,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAeT,KAAK;AACH,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAeT,KAAK;AACH,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAeT,KAAK;AACH,eAAO,MAAM,KAAK,kBAAkB;AAAA,MAEtC;AACE,eAAO,8BAAyB,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAU3C;AAAA,EACF;AAAA,EAEA,MAAc,kBAAkB,OAAgC;AAC9D,WAAO,iCAA0B,KAAK;AAAA;AAAA,6CAEJ,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAazC;AAAA,EAEQ,OAAO;AACb,YAAQ,IAAI,eAAM,KAAK,iDAA0C,CAAC;AAClE,YAAQ,IAAI,eAAM,KAAK,qCAAqC,CAAC;AAC7D,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF;","names":[]}